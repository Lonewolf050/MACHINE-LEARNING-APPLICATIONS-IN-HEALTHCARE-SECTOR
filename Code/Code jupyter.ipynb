{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ac8c26",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams \n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cebd8c",
   "metadata": {},
   "source": [
    "# reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv('heart.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad825033",
   "metadata": {},
   "source": [
    "# print head of datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ed94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458743d9",
   "metadata": {},
   "source": [
    "# Taking Care of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1a547",
   "metadata": {},
   "source": [
    "# Taking Care of Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data_dup = heart_data.duplicated().any()\n",
    "heart_data_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of duplicate rows in the original DataFrame\n",
    "print(\"Number of duplicate rows in original DataFrame:\", heart_data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING DUPLICATES\n",
    "heart_data = heart_data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data_dup =heart_data.duplicated().any()\n",
    "heart_data_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d05a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of duplicate rows in the new DataFrame\n",
    "print(\"Number of duplicate rows in new DataFrame:\", heart_data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ed69d",
   "metadata": {},
   "source": [
    "# coreleation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386807c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = heart_data.corr()\n",
    "\n",
    "# Plotting the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='plasma', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a 4x4 grid for subplots (or adjust as needed)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "\n",
    "\n",
    "# Flatten the axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define customization options\n",
    "hist_kwargs = {\n",
    "    'bins': 6,\n",
    "    'alpha': 1,  # Transparency\n",
    "    'edgecolor': 'black',\n",
    "    'color': 'mediumblue'\n",
    "}\n",
    "\n",
    "# Iterate through each column and create a histogram (limit to 14 columns)\n",
    "for i, column in enumerate(heart_data.columns[:14]):\n",
    "    axes[i].hist(heart_data[column], **hist_kwargs)\n",
    "    axes[i].set_title(column)\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout(w_pad=0, h_pad=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb21e6c",
   "metadata": {},
   "source": [
    "# model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features (X) and target variable (Y)\n",
    "X = heart_data.drop(columns='target', axis=1)\n",
    "Y = heart_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b71e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cbaad",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a89bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Logistic Regression accuracies\n",
    "print(\"Logistic Regression Accuracy:\")\n",
    "print(\"Training Accuracy:\", training_data_accuracy)\n",
    "print(\"Test Accuracy:\", test_data_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities on the test set\n",
    "Y_prob = model.predict_proba(X_test)[:, 1]\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(Y_test, Y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "average_precision = average_precision_score(Y_test, Y_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', label=f'Precision-Recall Curve (AUC = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.text(0.5, 0.2, f'Average Precision: {average_precision:.2f}', ha='center', va='center')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='red', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.text(0.5, 0.2, f'ROC AUC: {roc_auc:.2f}', ha='center', va='center')\n",
    "plt.show()\n",
    "\n",
    "# Print the scores\n",
    "print(f'Average Precision: {average_precision:.2f}')\n",
    "print(f'ROC AUC: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bc694",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77003680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b504f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on training data for KNN\n",
    "knn_train_prediction = knn_model.predict(X_train)\n",
    "knn_training_accuracy = accuracy_score(Y_train, knn_train_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test data for KNN\n",
    "knn_test_prediction = knn_model.predict(X_test)\n",
    "knn_test_accuracy = accuracy_score(Y_test, knn_test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Displaying K-Nearest Neighbors accuracies\n",
    "print(\"\\nK-Nearest Neighbors Accuracy:\")\n",
    "print(\"Training Accuracy:\", knn_training_accuracy)\n",
    "print(\"Test Accuracy:\", knn_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming knn_scores is defined for each K value\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25]  # Example K values\n",
    "knn_scores = [0.75, 0.82, 0.88, 0.90, 0.79, 0.81, 0.85, 0.88, 0.91, 0.84, 0.87, 0.80, 0.86]  # Remove one element\n",
    "\n",
    "# Plotting for KNN\n",
    "plt.plot(k_values, knn_scores, color='blue', marker='o')\n",
    "\n",
    "for k, score in zip(k_values, knn_scores):\n",
    "    plt.text(k, score, f'({k}, {score:.2f})')\n",
    "\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('K-Nearest Neighbors Scores for Different Numbers of Neighbors (K)')\n",
    "\n",
    "# Find the index of the maximum KNN score\n",
    "max_knn_score_index = knn_scores.index(max(knn_scores))\n",
    "max_knn_value = k_values[max_knn_score_index]\n",
    "\n",
    "# Print the highest KNN score in percentage and its corresponding K value\n",
    "plt.text(max_knn_value, max(knn_scores), f'Highest KNN Score: {max(knn_scores) * 100:.2f}% (K={max_knn_value})', ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621269a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed737897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403879c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on training data for Random Forest\n",
    "rf_train_prediction = rf_model.predict(X_train)\n",
    "rf_training_accuracy = accuracy_score(Y_train, rf_train_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test data for Random Forest\n",
    "rf_test_prediction = rf_model.predict(X_test)\n",
    "rf_test_accuracy = accuracy_score(Y_test, rf_test_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Random Forest accuracies\n",
    "print(\"\\nRandom Forest Accuracy:\")\n",
    "print(\"Training Accuracy:\", rf_training_accuracy)\n",
    "print(\"Test Accuracy:\", rf_test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming rf_scores is defined for each number of estimators\n",
    "n_estimators = [10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]  # Example number of estimators\n",
    "rf_scores = [0.78, 0.85, 0.88, 0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.95, 0.96]  # Example Random Forest scores\n",
    "\n",
    "# Plotting for Random Forest\n",
    "plt.plot(n_estimators, rf_scores, color='green', marker='o')\n",
    "\n",
    "for n, score in zip(n_estimators, rf_scores):\n",
    "    plt.text(n, score, f'({n}, {score:.2f})')\n",
    "\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Random Forest Scores for Different Numbers of Estimators')\n",
    "\n",
    "# Find the index of the maximum Random Forest score\n",
    "max_rf_score_index = rf_scores.index(max(rf_scores))\n",
    "max_rf_value = n_estimators[max_rf_score_index]\n",
    "\n",
    "# Print the highest Random Forest score and its corresponding number of estimators\n",
    "plt.text(max_rf_value, max(rf_scores), f'Highest RF Score: {max(rf_scores) * 100:.2f}% (Estimators={max_rf_value})', ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bafbde",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bda1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on training data for Decision Tree\n",
    "dt_train_prediction = dt_model.predict(X_train)\n",
    "dt_training_accuracy = accuracy_score(Y_train, dt_train_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test data for Decision Tree\n",
    "dt_test_prediction = dt_model.predict(X_test)\n",
    "dt_test_accuracy = accuracy_score(Y_test, dt_test_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Decision Tree accuracies\n",
    "print(\"\\nDecision Tree Accuracy:\")\n",
    "print(\"Training Accuracy:\", dt_training_accuracy)\n",
    "print(\"Test Accuracy:\", dt_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming dt_scores is defined for each number of maximum features\n",
    "max_features = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  # Example number of maximum features\n",
    "dt_scores = [0.78, 0.82, 0.85, 0.87, 0.89, 0.90, 0.91, 0.92, 0.93, 0.93, 0.94, 0.95, 0.96, 0.96]  # Example Decision Tree scores\n",
    "\n",
    "# Plotting for Decision Tree\n",
    "plt.plot(max_features, dt_scores, color='orange', marker='o')\n",
    "\n",
    "for f, score in zip(max_features, dt_scores):\n",
    "    plt.text(f, score, f'({f}, {score:.2f})')\n",
    "\n",
    "plt.xlabel('Number of Maximum Features')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Decision Tree Scores for Different Numbers of Maximum Features')\n",
    "\n",
    "# Find the index of the maximum Decision Tree score\n",
    "max_dt_score_index = dt_scores.index(max(dt_scores))\n",
    "max_dt_value = max_features[max_dt_score_index]\n",
    "\n",
    "# Print the highest Decision Tree score and its corresponding number of maximum features\n",
    "plt.text(max_dt_value, max(dt_scores), f'Highest DT Score: {max(dt_scores) * 100:.2f}% (Max Features={max_dt_value})', ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d47f74",
   "metadata": {},
   "source": [
    "# accuracies of all model used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the accuracy values for each model\n",
    "models = ['Logistic Regression', 'K-N Neighbors', 'Random Forest', 'Decision Tree']\n",
    "training_accuracies = [training_data_accuracy, knn_training_accuracy, rf_training_accuracy, dt_training_accuracy]\n",
    "test_accuracies = [test_data_accuracy, knn_test_accuracy, rf_test_accuracy, dt_test_accuracy]\n",
    "\n",
    "# Convert accuracy values to percentages\n",
    "training_accuracies_percent = [acc * 100 for acc in training_accuracies]\n",
    "test_accuracies_percent = [acc * 100 for acc in test_accuracies]\n",
    "\n",
    "# Plotting the bar chart\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "\n",
    "plt.bar(index, training_accuracies_percent, bar_width, label='Training Accuracy', color='blue')\n",
    "plt.bar(index + bar_width, test_accuracies_percent, bar_width, label='Test Accuracy', color='orange')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy Comparison between Training and Test Data')\n",
    "\n",
    "plt.xticks(index + bar_width / 2, models)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830104c",
   "metadata": {},
   "source": [
    "# prediction of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model variable is your trained Logistic Regression model\n",
    "\n",
    "# Sample input data for prediction (you can replace this with your own data)\n",
    "sample_data = np.array([43, 1, 0, 120, 177, 0, 0, 120, 1, 2.5, 1, 0, 3])\n",
    "\n",
    "# Reshape the input data to match the model's expectations\n",
    "sample_data = sample_data.reshape(1, -1)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(sample_data)\n",
    "\n",
    "# Display the prediction\n",
    "if prediction[0] == 1:\n",
    "    print(\"The model predicts that the individual has heart disease.\")\n",
    "else:\n",
    "    print(\"The model predicts that the individual does not have heart disease.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa80de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import joblib\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67394186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "\n",
    "def show_entry_fields():\n",
    "    p1 = int(e1.get())\n",
    "    p2 = int(e2.get())\n",
    "    p3 = int(e3.get())\n",
    "    p4 = int(e4.get())\n",
    "    p5 = int(e5.get())\n",
    "    p6 = int(e6.get())\n",
    "    p7 = int(e7.get())\n",
    "    p8 = int(e8.get())\n",
    "    p9 = int(e9.get())\n",
    "    p10 = float(e10.get())\n",
    "    p11 = int(e11.get())\n",
    "    p12 = int(e12.get())\n",
    "    p13 = int(e13.get())\n",
    "    \n",
    "    model = joblib.load('model_joblib_heart')\n",
    "    result = model.predict([[p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13]])\n",
    "    \n",
    "    result_text = \"No Heart Disease\" if result == 0 else \"Possibility of Heart Disease\"\n",
    "    \n",
    "    # Display the result in a pop-up message box\n",
    "    messagebox.showinfo(\"Prediction Result\", result_text)\n",
    "\n",
    "    \n",
    "    \n",
    "master = Tk()\n",
    "master.title(\"Heart Disease Prediction System\")\n",
    "\n",
    "\n",
    "label = Label(master, text = \"Heart Disease Prediction System\"\n",
    "                          , bg = \"black\", fg = \"white\"). \\\n",
    "                               grid(row=0,columnspan=2)\n",
    "\n",
    "\n",
    "Label(master, text=\"Enter Your Age\").grid(row=1)\n",
    "Label(master, text=\"Male Or Female [1/0]\").grid(row=2)\n",
    "Label(master, text=\"Enter Value of CP\").grid(row=3)\n",
    "Label(master, text=\"Enter Value of trestbps\").grid(row=4)\n",
    "Label(master, text=\"Enter Value of chol\").grid(row=5)\n",
    "Label(master, text=\"Enter Value of fbs\").grid(row=6)\n",
    "Label(master, text=\"Enter Value of restecg\").grid(row=7)\n",
    "Label(master, text=\"Enter Value of thalach\").grid(row=8)\n",
    "Label(master, text=\"Enter Value of exang\").grid(row=9)\n",
    "Label(master, text=\"Enter Value of oldpeak\").grid(row=10)\n",
    "Label(master, text=\"Enter Value of slope\").grid(row=11)\n",
    "Label(master, text=\"Enter Value of ca\").grid(row=12)\n",
    "Label(master, text=\"Enter Value of thal\").grid(row=13)\n",
    "\n",
    "\n",
    "\n",
    "e1 = Entry(master)\n",
    "e2 = Entry(master)\n",
    "e3 = Entry(master)\n",
    "e4 = Entry(master)\n",
    "e5 = Entry(master)\n",
    "e6 = Entry(master)\n",
    "e7 = Entry(master)\n",
    "e8 = Entry(master)\n",
    "e9 = Entry(master)\n",
    "e10 = Entry(master)\n",
    "e11 = Entry(master)\n",
    "e12 = Entry(master)\n",
    "e13 = Entry(master)\n",
    "\n",
    "e1.grid(row=1, column=1)\n",
    "e2.grid(row=2, column=1)\n",
    "e3.grid(row=3, column=1)\n",
    "e4.grid(row=4, column=1)\n",
    "e5.grid(row=5, column=1)\n",
    "e6.grid(row=6, column=1)\n",
    "e7.grid(row=7, column=1)\n",
    "e8.grid(row=8, column=1)\n",
    "e9.grid(row=9, column=1)\n",
    "e10.grid(row=10, column=1)\n",
    "e11.grid(row=11, column=1)\n",
    "e12.grid(row=12, column=1)\n",
    "e13.grid(row=13, column=1)\n",
    "\n",
    "\n",
    "\n",
    "Button(master, text='Predict', command=show_entry_fields).grid()\n",
    "\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\aman0\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aman0\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('model_joblib_heart')\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        # Get user input from the form\n",
    "        features = [float(x) for x in request.form.values()]\n",
    "\n",
    "        # Make a prediction using the model\n",
    "        result = model.predict([features])[0]\n",
    "\n",
    "        # Display the result in a user-friendly way\n",
    "        result_text = \"No Heart Disease\" if result == 0 else \"Possibility of Heart Disease\"\n",
    "\n",
    "        return render_template('index.html', result=result_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
